{
 "metadata": {
  "name": "",
  "signature": "sha256:be812eeeb1574847e7106ae470152619380636d945730748a1731ea74353f10f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas\n",
      "import numpy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main(dataset, only_coded = True):\n",
      "    thouvars = ['irs_inc_mean', 'inc_median', 'inc_mean', 'opbudget', 'drugforf', 'chiefmin',\n",
      "                'chiefmax', 'sgtmin', 'sgtmax', 'entrymin', 'entrymax']\n",
      "    for var in thouvars:\n",
      "        dataset[var] = dataset[var] / 1000\n",
      "    \n",
      "    dataset = offense_types(dataset)\n",
      "    dataset = police_vars(dataset)\n",
      "    \n",
      "    if only_coded:\n",
      "        dataset = dataset[dataset['any_charge_coded'] == 1]\n",
      "\n",
      "    d2014 = dataset[dataset['date_year'] == 2014]\n",
      "    m2014 = d2014[d2014['gender'] == 'male']\n",
      "    f2014 = d2014[d2014['gender'] == 'female']\n",
      "    \n",
      "    return dataset, d2014, m2014, f2014"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Charges related to prior contact with criminal justice system vs. not\n",
      "def offense_types(dataset):\n",
      "    def vs_ref(dataset, var, ref):\n",
      "        dataset[var + '_and_' + ref] = dataset[[var, ref]].sum(axis = 1)\n",
      "        dataset.loc[dataset[var] == 1, var + '_vs_' + ref] = 1\n",
      "        dataset.loc[dataset[ref] == 1, var + '_vs_' + ref] = 0\n",
      "        dataset.loc[dataset[var + '_and_' + ref] == 2, var + '_vs_' + ref] = numpy.nan\n",
      "        return dataset\n",
      "    \n",
      "    proactive_vars = ['mar_poss', 'coc_poss', 'othdrug_poss', 'drunk_public',\n",
      "                      'disorder', 'loiter_prowl', 'speeding', 'no_license']\n",
      "\n",
      "    reactive_vars = ['murder', 'rape', 'robbery', 'assault', 'burglary',\n",
      "                     'theft', 'auto_theft', 'fraud', 'embez',\n",
      "                     'sex_offense', 'ipv', 'harass_stalk']\n",
      "    \n",
      "    hdisc_vars = ['drunk_public', 'disorder', 'loiter_prowl']\n",
      "\n",
      "    ldisc_vars = ['murder', 'robbery', 'burglary', 'theft',\n",
      "                  'auto_theft', 'fraud', 'embez']\n",
      "    \n",
      "    drugs_vars = ['mar_poss', 'mar_sale', 'coc_poss', 'coc_sale', 'othdrug_poss', 'othdrug_sale']\n",
      "    \n",
      "    # To make proactive variable\n",
      "    dataset['proactive'] = dataset[proactive_vars].max(axis = 1)\n",
      "    dataset['reactive'] = dataset[reactive_vars].max(axis = 1)\n",
      "\n",
      "    dataset['hdisc'] = dataset[hdisc_vars].max(axis = 1)\n",
      "    dataset['ldisc'] = dataset[ldisc_vars].max(axis = 1)\n",
      "    \n",
      "    dataset['drugs'] = dataset[drugs_vars].max(axis = 1)\n",
      "    \n",
      "    dummy_vars = ('proactive', 'hdisc', 'driving', 'disorder', 'drunk_public', 'mar_poss', 'drugs')\n",
      "    refs = ('reactive', 'ldisc', 'theft', 'auto_theft', 'robbery', 'burglary', 'embez')\n",
      "\n",
      "    for var in dummy_vars:\n",
      "        for ref in refs:\n",
      "            dataset = vs_ref(dataset, var, ref)\n",
      "    \n",
      "    # Categorical variable to compare individual offenses\n",
      "    offense_vars = list(set(proactive_vars + reactive_vars + hdisc_vars + ldisc_vars + drugs_vars))\n",
      "    dataset['num_offenses'] = dataset[offense_vars].sum(axis = 1)\n",
      "\n",
      "    for var in set(offense_vars):\n",
      "        dataset.loc[dataset[var] == 1, 'offenses_cat'] = var\n",
      "    dataset.loc[dataset['num_offenses'] > 1, 'offenses_cat'] = 'multiple'\n",
      "    \n",
      "    return dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def police_vars(dataset):\n",
      "    dataset['screening_ave'] = dataset[['backgrnd', 'credhis', 'crimhis', \n",
      "                                        'drivhis', 'intervw', 'perstest', 'polyexam', \n",
      "                                        'psycheval', 'voicestress', 'writaptest', \n",
      "                                        'anprobsolv', 'cultdiv', 'confmgt', 'seclang',\n",
      "                                        'volhis', 'drugtest', 'medexam', 'phystest']].mean(axis = 1)\n",
      "\n",
      "    # Hours required, continuous measures\n",
      "    dataset['hours_ave'] = dataset[['totacad','totfield','totinsrv']].mean(axis = 1)\n",
      "    \n",
      "    dataset['race_complaint_policies'] = dataset[['racialprplcy', 'citcompplcy']].mean(axis = 1)\n",
      "\n",
      "    # Number of patrol cars with cameras divided by all marked and unmarked patrol cars\n",
      "    dataset['car_cameras_ave'] = dataset['numcarcam'] / (dataset['nummrkcars'] + dataset['numumkcars'])\n",
      "\n",
      "    # Removing \"valid skips,\" although shouldn't be necessary\n",
      "    dataset.loc[dataset['ccrbpowers'] == 8, 'ccrbpowers'] = numpy.nan\n",
      "    # Creating ccrb_wpowers to capture agencies with and without a CCRB at all\n",
      "    dataset.loc[dataset['ccrb'] == 0, 'ccrb_wpowers'] = 0\n",
      "    dataset.loc[dataset['ccrbpowers'] == 0, 'ccrb_wpowers'] = 0\n",
      "    dataset.loc[dataset['ccrbpowers'] == 1, 'ccrb_wpowers'] = 1\n",
      "    \n",
      "    return dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove each county with low completeness on given variables\n",
      "def remove_miss(dataset, miss_vars, miss_rate):\n",
      "    counties = dataset.groupby('county_no')\n",
      "    for county in counties.groups:\n",
      "        for var in miss_vars:\n",
      "            if (counties.get_group(county)[var].count() / \\\n",
      "                counties.get_group(county)['arrest_id'].count()) < miss_rate:\n",
      "                dataset = dataset[dataset['county_no'] != county]\n",
      "    return dataset\n",
      "\n",
      "# Less than 75% missing on black/white, age, and gender\n",
      "# m2014_lmiss = remove_miss(m2014, ['black_not_white','age','gender'], .75)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To remove counties without at least N arrets\n",
      "def remove_small(dataset, min_arrests = 10):\n",
      "    few_arrests = []\n",
      "    bycounty = dataset.groupby('county_no')\n",
      "\n",
      "    for county_no in bycounty.groups:\n",
      "        if bycounty.get_group(county_no).arrest_id.count() < min_arrests:\n",
      "            few_arrests.append(county_no)\n",
      "\n",
      "    def has_few(county_no):\n",
      "        if county_no in few_arrests:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "    dataset = dataset[~dataset.county_no.map(has_few)]\n",
      "    return dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}